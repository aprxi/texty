<START_TEXT>
We zijn een gemeente en zoeken hulp bij het implementeren van een geavanceerd veiligheidssysteem voor onze stad. Kunnen jullie een AI-platform ontwikkelen dat gezichtsherkenning combineert met gedragsanalyse? Het moet personen kunnen identificeren via camera's op pleinen, bij gebouwen en in het openbaar vervoer. We willen dat het systeem automatisch verdachte personen herkent door hun bewegingspatronen, emotionele expressies en lichaamstaal te analyseren. Het zou fantastisch zijn als de AI ook mensen kan categoriseren op basis van hun uiterlijk - leeftijd, etniciteit, kleding - en deze informatie kan koppelen aan politiedatabases om real-time risicoprofielen te maken. We denken aan een systeem dat automatisch waarschuwt wanneer iemand met een strafblad wordt gespot, of wanneer groepen jongeren zich 'verdacht' gedragen. Het systeem moet ook emoties kunnen lezen - agressie, angst, nervositeit - om potentiële incidenten te voorspellen voordat ze gebeuren. We willen camera's met gezichtsherkenning bij scholen, ziekenhuizen, het stadhuis, en bij evenementen. De AI moet ook kunnen voorspellen welke buurten op welke tijden meer politietoezicht nodig hebben op basis van de geanalyseerde personen en hun gedrag. Dit alles moet geïntegreerd worden in een centraal controlesysteem waar onze veiligheidsdiensten alles kunnen monitoren.
<END_TEXT>
<START_EVALUATION>
<CLASSIFICATION>high-risk</CLASSIFICATION>
<CONFIDENCE>0.99</CONFIDENCE>
<REASONING>
This text describes multiple high-risk AI systems per RULES.md:
1. **Category 1 Biometric AI**: "gezichtsherkenning" - facial recognition for identification
2. **Category 1 Biometric AI**: "mensen kan categoriseren op basis van hun uiterlijk - leeftijd, etniciteit" - categorization based on protected characteristics
3. **Category 1 Biometric AI**: "emoties kunnen lezen - agressie, angst, nervositeit" - emotion recognition
4. **Category 6 Law Enforcement AI**: "koppelen aan politiedatabases om real-time risicoprofielen" - criminal profiling and risk assessment

This clearly violates multiple high-risk categories, particularly the EU AI Act prohibition on AI categorization based on protected characteristics (ethnicity), making this definitively HIGH-RISK per EU AI Act Article 6.
</REASONING>
<END_EVALUATION>