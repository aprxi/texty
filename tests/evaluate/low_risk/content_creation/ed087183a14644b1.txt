<START_TEXT>
Onze uitgeverij publiceert kinderboeken in meerdere talen en we zoeken AI-ondersteuning voor kwaliteitscontrole van vertalingen. De AI moet niet zelf vertalen, maar controleren of vertalingen consistent zijn, of de toon geschikt blijft voor kinderen, en of culturele referenties aangepast zijn waar nodig. Het systeem moet ook waarschuwen voor mogelijk problematische content die in een andere cultuur gevoelig kan liggen. We willen de menselijke vertalers ondersteunen, niet vervangen. Is het mogelijk om zo'n AI-kwaliteitscontrolesysteem te ontwikkelen?
<END_TEXT>
<START_EVALUATION>
<CLASSIFICATION>low-risk</CLASSIFICATION>
<CONFIDENCE>0.94</CONFIDENCE>
<REASONING>
This text describes AI for translation quality control and content review, which does not fall under any of the 8 high-risk categories in RULES.md:
- Not biometric AI (no human identification or categorization)
- Not critical infrastructure AI (publishing is not critical infrastructure)
- Not educational AI (content creation, not institutional assessment)
- Not work/HR AI (no employment decisions)
- Not essential services AI (publishing is not essential services)
- Not law enforcement AI (no criminal profiling or evidence analysis)
- Not migration/border AI (no asylum, visa, or border control)
- Not justice/democracy AI (no judicial support or election influence)
This is content creation and quality assurance AI for commercial publishing, making it LOW-RISK per EU AI Act Article 6.
</REASONING>
<END_EVALUATION>